{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9cdf68",
   "metadata": {},
   "source": [
    "# Notebook 1 : Extraction et Ingestion des Données vers GCS\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Ce notebook permet d'**extraire les données** depuis diverses sources publiques et de les **ingérer dans Google Cloud Storage (GCS)** dans la couche \"bronze\" (données brutes). Il constitue la première étape du pipeline ETL :\n",
    "\n",
    "- **Extraction** : Téléchargement des données depuis les APIs publiques (Île-de-France Mobilités, Éducation Nationale, Calendrier Gouv, Open-Meteo, GeoAPI)\n",
    "- **Ingestion** : Upload des données brutes vers GCS pour stockage et traitement ultérieur\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
    "\n",
    "1. **Notebook 0 exécuté avec succès** : La connexion à GCS doit être validée\n",
    "2. **Fichier `.env` configuré** à la racine du projet avec :\n",
    "   - `PROJECT_ID` : l'identifiant de votre projet GCP\n",
    "   - `GOOGLE_APPLICATION_CREDENTIALS` : le chemin vers votre fichier de credentials JSON\n",
    "   - `BUCKET_NAME` : le nom de votre bucket GCS\n",
    "3. **Service Account** avec les permissions :\n",
    "   - `Storage Admin` ou `Storage Object Creator` pour GCS\n",
    "4. **Packages Python installés** :\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "   \n",
    "Une fois ce notebook exécuté avec succès, vous pouvez passer au :\n",
    "- **Notebook 2** : Chargement des données depuis GCS vers BigQuery (couche \"silver\") et transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9ac0e",
   "metadata": {},
   "source": [
    "## 0 - Configuration\n",
    "\n",
    "- Chargement des variables d'environnement depuis `.env`\n",
    "- Initialisation des chemins et identifiants du projet\n",
    "- Création du dossier local `data/` pour le stockage temporaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3643f03e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROOT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moauth2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service_account\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m sys.path.append(\u001b[38;5;28mstr\u001b[39m(\u001b[43mROOT\u001b[49m))\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgcs_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     download_parquet_from_idfm,\n\u001b[32m     18\u001b[39m     upload_to_gcs,\n\u001b[32m     19\u001b[39m     upload_folder_to_gcs,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m load_dotenv()\n",
      "\u001b[31mNameError\u001b[39m: name 'ROOT' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.gcs_utils import (\n",
    "    download_parquet_from_idfm,\n",
    "    upload_to_gcs,\n",
    "    upload_folder_to_gcs,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8de4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentification Google Cloud\n",
    "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f9428",
   "metadata": {},
   "source": [
    "## 1 - Données Historiques de Validations\n",
    "\n",
    "**Source** : API Île-de-France Mobilités (`histo-validations-reseau-ferre`)\n",
    "\n",
    "**Format** : Fichiers ZIP contenant des CSV/TXT (2015-2024)\n",
    "\n",
    "**Processus** :\n",
    "1. Récupération de la liste des fichiers via l'API\n",
    "2. Téléchargement et extraction des archives ZIP\n",
    "3. Upload vers GCS (filtrage `*_NB_FER.txt` et `*_NB_FER.csv` case-insensitive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ade6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers trouvés: 10\n",
      "\n",
      "Fichiers disponibles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annee</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>data-rf-2017.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>data-rf-2019.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>data-rf-2020.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>data-rf-2021.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>data-rf-2018.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>data-rf-2016.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>data-rf-2022.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>data-rf-2024.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>data-rf-2015.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>data-rf-2023.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annee          filename                                                url\n",
       "0   2017  data-rf-2017.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "1   2019  data-rf-2019.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "2   2020  data-rf-2020.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "3   2021  data-rf-2021.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "4   2018  data-rf-2018.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "5   2016  data-rf-2016.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "6   2022  data-rf-2022.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "7   2024  data-rf-2024.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "8   2015  data-rf-2015.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "9   2023  data-rf-2023.zip  https://data.iledefrance-mobilites.fr/api/expl..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1 - Récupération des liens des fichiers depuis l'API ile de de France Mobilités\n",
    "URL = \"https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/datasets/histo-validations-reseau-ferre/records\"\n",
    "\n",
    "response = requests.get(URL, timeout=60)\n",
    "response.raise_for_status()\n",
    "\n",
    "records = response.json().get(\"results\", [])\n",
    "print(f\"Nombre de fichiers trouvés: {len(records)}\")\n",
    "\n",
    "df_metadata = pd.DataFrame([\n",
    "    {\n",
    "        'annee': int(r['annee']),\n",
    "        'filename': r['reseau_ferre']['filename'],\n",
    "        'url': r['reseau_ferre']['url']\n",
    "    }\n",
    "    for r in records\n",
    "])\n",
    "\n",
    "print(\"\\nFichiers disponibles:\")\n",
    "display(df_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f671d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement 2017 (data-rf-2017.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2017\n",
      "[...] - Téléchargement 2019 (data-rf-2019.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2019\n",
      "[...] - Téléchargement 2020 (data-rf-2020.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2020\n",
      "[...] - Téléchargement 2021 (data-rf-2021.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2021\n",
      "[...] - Téléchargement 2018 (data-rf-2018.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2018\n",
      "[...] - Téléchargement 2016 (data-rf-2016.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2016\n",
      "[...] - Téléchargement 2022 (data-rf-2022.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2022\n",
      "[...] - Téléchargement 2024 (data-rf-2024.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2024\n",
      "[...] - Téléchargement 2015 (data-rf-2015.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2015\n",
      "[...] - Téléchargement 2023 (data-rf-2023.zip)\n",
      "    [OK] - Téléchargé\n",
      "    [OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2023\n",
      "\n",
      "[OK] - Terminé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre\n"
     ]
    }
   ],
   "source": [
    "# 1.2 - Téléchargement des fichiers\n",
    "BASE_DIR = DATA_DIR / \"histo-validations-reseau-ferre\"\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for row in df_metadata.itertuples():\n",
    "    year_dir = BASE_DIR / str(row.annee)\n",
    "    year_dir.mkdir(exist_ok=True)\n",
    "    zip_path = year_dir / row.filename\n",
    "\n",
    "    print(f\"[...] - Téléchargement {row.annee} ({row.filename})\")\n",
    "    try:\n",
    "        response = requests.get(row.url, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        zip_path.write_bytes(response.content)\n",
    "        print(f\"    [OK] - Téléchargé\")\n",
    "        \n",
    "        with ZipFile(zip_path) as zf:\n",
    "            zf.extractall(year_dir)\n",
    "        print(f\"    [OK] - Extrait dans {year_dir}\")\n",
    "        \n",
    "        zip_path.unlink()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Erreur] {row.annee}: {e}\")\n",
    "\n",
    "print(f\"\\n[OK] - Terminé: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f9057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Upload] - Upload des données historiques vers GCS...\n",
      "[...] - Upload du dossier histo-validations-reseau-ferre vers GCS...\n",
      "[...] - Extensions filtrées: .csv, .txt\n",
      "  ✓ 2022/data-rf-2022/2022_S2_PROFIL_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S1_NB_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S1_PROFIL_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S2_NB_FER.txt\n",
      "  ✓ 2024/2024_S1_PROFIL_FER.txt\n",
      "  ✓ 2024/2024_S1_NB_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S2_PROFIL_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S1_NB_FER .txt\n",
      "  ✓ 2023/data-rf-2023/2023_S2_NB_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S1_PROFIL_FER.txt\n",
      "  ✓ 2015/data-rf-2015/2015S2_NB_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S1_PROFIL_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S2_PROFIL_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S1_NB_FER.csv\n",
      "  ✓ 2017/data-rf-2017/2017_S2_PROFIL_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017_S2_NB_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017S1_PROFIL_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017S1_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S2_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S2_PROFIL_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S1_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S1_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S1_NB_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S1_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S2_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S2_NB_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S2_NB_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S1_PROFIL_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S2_PROFIL_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S1_NB_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S1_NB_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S2_Profil_Fer.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S1_PROFIL_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S2_NB_Fer.txt\n",
      "  ✓ 2016/data-rf-2016/2016S2_NB_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S2_PROFIL_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S1_NB_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S1_PROFIL_FER.txt\n",
      "[OK] - 38 fichiers uploadés\n",
      "[OK] - 5 fichiers ignorés (extension non autorisée)\n",
      "[OK] - Taille totale: 1091.79 MB\n",
      "[OK] - Dossier GCS: gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 - Upload vers GCS\n",
    "print(f\"[Upload] - Upload des données historiques vers GCS...\")\n",
    "upload_folder_to_gcs(\n",
    "    folder_path=BASE_DIR,\n",
    "    storage_client=storage_client,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    gcs_folder=\"bronze\", \n",
    "    gcs_subfolder=\"histo-validations-reseau-ferre\", \n",
    "    extensions=[\".csv\", \".txt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314ed16",
   "metadata": {},
   "source": [
    "## 2 - Emplacement des Gares\n",
    "\n",
    "**Source** : API Île-de-France Mobilités (`emplacement-des-gares-idf`)\n",
    "\n",
    "**Format** : Parquet\n",
    "\n",
    "**Processus** : Téléchargement direct depuis l'API et upload vers GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f65dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet emplacement-des-gares-idf...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\n",
      "[OK] - Taille: 0.20 MB\n",
      "[...] - Upload de emplacement-des-gares-idf.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\n",
      "[OK] - Taille: 0.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 - Récupération du fichier CSV depuis l'API ile de de France Mobilités\n",
    "dl_path_gares = download_parquet_from_idfm('emplacement-des-gares-idf', data_dir=DATA_DIR)\n",
    "upload_to_gcs(\n",
    "    file_path=dl_path_gares,\n",
    "    storage_client=storage_client,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    gcs_folder=\"bronze\",\n",
    "    gcs_subfolder=\"emplacement-des-gares-idf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce02ec1",
   "metadata": {},
   "source": [
    "## 3 - Référentiel des Lignes\n",
    "\n",
    "**Source** : API Île-de-France Mobilités (`referentiel-des-lignes`)\n",
    "\n",
    "**Format** : Parquet\n",
    "\n",
    "**Processus** : Téléchargement direct depuis l'API et upload vers GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccbad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet referentiel-des-lignes...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/referentiel-des-lignes/referentiel-des-lignes.parquet\n",
      "[OK] - Taille: 0.18 MB\n",
      "[...] - Upload de referentiel-des-lignes.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet\n",
      "[OK] - Taille: 0.18 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 - Téléchargement direct du fichier Parquet depuis l'API IDFM\n",
    "dl_path_lignes = download_parquet_from_idfm('referentiel-des-lignes', data_dir=DATA_DIR)\n",
    "upload_to_gcs(\n",
    "    file_path=dl_path_lignes,\n",
    "    storage_client=storage_client,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    gcs_folder=\"bronze\",\n",
    "    gcs_subfolder=\"referentiel-des-lignes\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be07d9",
   "metadata": {},
   "source": [
    "## 4 - Arrêts\n",
    "\n",
    "**Source** : API Île-de-France Mobilités (`arrets`)\n",
    "\n",
    "**Format** : Parquet\n",
    "\n",
    "**Processus** : Téléchargement direct depuis l'API et upload vers GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70661a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet arrets...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/arrets/arrets.parquet\n",
      "[OK] - Taille: 2.77 MB\n",
      "[...] - Upload de arrets.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/arrets/arrets.parquet\n",
      "[OK] - Taille: 2.77 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/arrets/arrets.parquet'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 - Téléchargement direct du fichier Parquet depuis l'API IDFM\n",
    "dl_path_arrets = download_parquet_from_idfm('arrets', data_dir=DATA_DIR)\n",
    "upload_to_gcs(\n",
    "    file_path=dl_path_arrets,\n",
    "    storage_client=storage_client,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    gcs_folder=\"bronze\",\n",
    "    gcs_subfolder=\"arrets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3102fe32",
   "metadata": {},
   "source": [
    "## 5 - Vacances\n",
    "### 5.1 - Vacances Scolaires\n",
    "- **Source** : Data Gouv - Éducation Nationale (`fr-en-calendrier-scolaire`)\n",
    "- **Format** : CSV\n",
    "- **Processus** : Téléchargement direct et upload vers GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 - Vacances Scolaires\n",
    "URL = \"https://data.education.gouv.fr/explore/dataset/fr-en-calendrier-scolaire/download/?format=csv\"\n",
    "OUTPUT_FILE = \"vacances_scolaires.csv\"\n",
    "\n",
    "vacances_dir = DATA_DIR / \"vacances-scolaires\"\n",
    "vacances_dir.mkdir(exist_ok=True)\n",
    "csv_path = vacances_dir / OUTPUT_FILE\n",
    "\n",
    "print(f\"[...] - Téléchargement des données de vacances scolaires...\")\n",
    "response = requests.get(URL, timeout=120)\n",
    "response.raise_for_status()\n",
    "\n",
    "csv_path.write_bytes(response.content)\n",
    "\n",
    "file_size_mb = csv_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"[OK] - Téléchargé: {csv_path}\")\n",
    "print(f\"[OK] - Taille: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# Upload vers GCS\n",
    "upload_to_gcs(\n",
    "    file_path=csv_path,\n",
    "    storage_client=storage_client,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    gcs_folder=\"bronze\",\n",
    "    gcs_subfolder=\"vacances-scolaires\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201eab4b",
   "metadata": {},
   "source": [
    "### 5.2 - Jours Fériés\n",
    "- **Source** : API Calendrier Gouv (https://calendrier.api.gouv.fr/jours-feries/)\n",
    "- **Format** : JSON (un fichier par année)\n",
    "- **Processus** : Téléchargement pour plusieurs années (2015-2026) et upload vers GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c703082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement des jours fériés de 2015 à 2026...\n",
      "[OK] - 2015: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2015.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2015.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2016: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2016.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2016.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2017: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2017.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2017.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2018: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2018.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2018.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2019: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2019.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2019.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2020: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2020.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2020.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2021: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2021.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2021.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2022: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2022.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2022.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2023: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2023.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2023.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2024: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2024.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2024.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2025: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2025.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2025.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2026: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2026.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2026.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "\n",
      "[OK] - Terminé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/jours-feries\n"
     ]
    }
   ],
   "source": [
    "# 5.2 - Jours Fériés (API Gouv) - Plusieurs années\n",
    "start_year = 2015\n",
    "end_year = datetime.now().year + 1\n",
    "\n",
    "feries_dir = DATA_DIR / \"jours-feries\"\n",
    "feries_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"[...] - Téléchargement des jours fériés de {start_year} à {end_year}...\")\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    URL = f\"https://calendrier.api.gouv.fr/jours-feries/metropole/{year}.json\"\n",
    "    json_path = feries_dir / f\"jours_feries_{year}.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        feries = response.json()\n",
    "        json_path.write_text(json.dumps(feries, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        \n",
    "        print(f\"[OK] - {year}: {len(feries)} jours fériés\")\n",
    "        \n",
    "        # Upload vers GCS\n",
    "        upload_to_gcs(\n",
    "            file_path=json_path,\n",
    "            storage_client=storage_client,\n",
    "            bucket_name=BUCKET_NAME,\n",
    "            gcs_folder=\"bronze\",\n",
    "            gcs_subfolder=\"jours-feries\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Erreur] - {year}: {e}\")\n",
    "\n",
    "print(f\"\\n[OK] - Terminé: {feries_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
