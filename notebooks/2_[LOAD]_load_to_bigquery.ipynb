{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557bd78a",
   "metadata": {},
   "source": [
    "# Notebook 2 : Chargement des Données vers BigQuery (LOAD)\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Ce notebook permet de **charger les données depuis Google Cloud Storage (GCS) vers BigQuery** pour créer la couche \"silver\" du pipeline ETL. \n",
    "\n",
    "Les données brutes stockées dans GCS (couche \"bronze\") sont chargées dans BigQuery.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
    "\n",
    "1. **Exécuté le notebook `1_[EXTRACT]_ingest_to_gcs.ipynb`** pour avoir des données dans GCS\n",
    "2. **Fichier `.env` configuré** avec les variables d'environnement nécessaires\n",
    "3. **Service Account** avec les permissions BigQuery (`BigQuery Data Editor`, `BigQuery Job User`)\n",
    "4. **Packages Python installés** : `google-cloud-bigquery`, `google-cloud-storage`, `pandas`, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962f99c",
   "metadata": {},
   "source": [
    "## 1 - Configuration et Authentification\n",
    "\n",
    "Cette section configure l'environnement et établit la connexion avec BigQuery et GCS.\n",
    "\n",
    "**Étapes :**\n",
    "- Import des bibliothèques nécessaires\n",
    "- Chargement des variables d'environnement depuis `.env`\n",
    "- Authentification avec le Service Account\n",
    "- Création des clients BigQuery et GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac220fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Configuration et imports terminés\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.bq_utils import (\n",
    "    load_csv_from_gcs,\n",
    "    load_parquet_from_gcs,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "DATASET_ID = \"silver\"\n",
    "\n",
    "# Authentification\n",
    "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
    "bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=creds)\n",
    "\n",
    "print(\"[OK] - Configuration et imports terminés\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1044d",
   "metadata": {},
   "source": [
    "### 1.1 - Création du Dataset BigQuery\n",
    "\n",
    "Création du dataset \"silver\" s'il n'existe pas déjà. Le dataset est l'équivalent d'un schéma dans une base de données relationnelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8781b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Dataset silver existe déjà\n"
     ]
    }
   ],
   "source": [
    "# Création du dataset s'il n'existe pas\n",
    "dataset_ref = bq_client.dataset(DATASET_ID)\n",
    "try:\n",
    "    bq_client.get_dataset(dataset_ref)\n",
    "    print(f\"[OK] - Dataset {DATASET_ID} existe déjà\")\n",
    "except Exception:\n",
    "    dataset = bigquery.Dataset(dataset_ref)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = bq_client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"[OK] - Dataset {DATASET_ID} créé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c77f9",
   "metadata": {},
   "source": [
    "## 2 - Chargement des Tables de Dimension\n",
    "\n",
    "Les tables de dimension contiennent les données de référence qui seront utilisées pour enrichir les tables de fait. Elles sont généralement stables dans le temps.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 - Table `dim_gare` (Emplacement des Gares)\n",
    "\n",
    "Cette table contient les informations géographiques et descriptives de toutes les gares d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Défini manuellement avec clé primaire `id_gares`\n",
    "- **Types de données** : Géographie (GEOGRAPHY), entiers, chaînes de caractères\n",
    "- **Clé primaire** : `id_gares` (mode REQUIRED)\n",
    "\n",
    "**Note** : Le schéma manuel permet de contrôler précisément les types de données, notamment pour les colonnes géographiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb26fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement direct depuis GCS (bronze) vers BigQuery (silver) avec schéma manuel\n",
    "gcs_path_gares = \"bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\"\n",
    "\n",
    "# Définition du schéma manuel avec clé primaire (id_gares)\n",
    "schema_gares = [\n",
    "    bigquery.SchemaField(\"geo_point_2d\", \"GEOGRAPHY\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"geo_shape\", \"GEOGRAPHY\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_gares\", \"INTEGER\", mode=\"REQUIRED\", description=\"Clé primaire\"),\n",
    "    bigquery.SchemaField(\"nom_gares\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_so_gar\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_su_gar\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_ref_zdc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_zdc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_ref_zda\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_zda\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idrefliga\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idrefligc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"res_com\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"indice_lig\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mode\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tertrain\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"terrer\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"termetro\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tertram\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"terval\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"exploitant\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idf\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"principal\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"x\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"y\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"picto\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_iv\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "table_id = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_gares,\n",
    "    table_name=\"gares\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=schema_gares,\n",
    "    primary_key=\"id_gares\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df54d0",
   "metadata": {},
   "source": [
    "### 2.2 - Vérification de la Table `dim_gare`\n",
    "\n",
    "Après le chargement, on vérifie que les données ont été correctement chargées en :\n",
    "- Affichant le nombre de lignes\n",
    "- Listant les colonnes et leurs types\n",
    "- Afficant un aperçu des données (5 premières lignes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6688f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Nombre total de lignes: 1234\n",
      "[OK] - Colonnes:\n",
      "  - geo_point_2d: GEOGRAPHY\n",
      "  - geo_shape: GEOGRAPHY\n",
      "  - id_gares: INTEGER\n",
      "  - nom_gares: STRING\n",
      "  - nom_so_gar: STRING\n",
      "  - nom_su_gar: STRING\n",
      "  - id_ref_zdc: INTEGER\n",
      "  - nom_zdc: STRING\n",
      "  - id_ref_zda: INTEGER\n",
      "  - nom_zda: STRING\n",
      "  - idrefliga: STRING\n",
      "  - idrefligc: STRING\n",
      "  - res_com: STRING\n",
      "  - indice_lig: STRING\n",
      "  - mode: STRING\n",
      "  - tertrain: STRING\n",
      "  - terrer: STRING\n",
      "  - termetro: STRING\n",
      "  - tertram: STRING\n",
      "  - terval: STRING\n",
      "  - exploitant: STRING\n",
      "  - idf: INTEGER\n",
      "  - principal: INTEGER\n",
      "  - x: FLOAT\n",
      "  - y: FLOAT\n",
      "  - picto: STRING\n",
      "  - nom_iv: STRING\n",
      "\n",
      "[OK] - Aperçu des données (5 premières lignes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>geo_shape</th>\n",
       "      <th>id_gares</th>\n",
       "      <th>nom_gares</th>\n",
       "      <th>nom_so_gar</th>\n",
       "      <th>nom_su_gar</th>\n",
       "      <th>id_ref_zdc</th>\n",
       "      <th>nom_zdc</th>\n",
       "      <th>id_ref_zda</th>\n",
       "      <th>nom_zda</th>\n",
       "      <th>...</th>\n",
       "      <th>termetro</th>\n",
       "      <th>tertram</th>\n",
       "      <th>terval</th>\n",
       "      <th>exploitant</th>\n",
       "      <th>idf</th>\n",
       "      <th>principal</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>picto</th>\n",
       "      <th>nom_iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT(2.57064006889043 49.0100449600405)</td>\n",
       "      <td>POINT(2.57064006889043 49.0100449600405)</td>\n",
       "      <td>1004</td>\n",
       "      <td>Parc PX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>73595</td>\n",
       "      <td>NC</td>\n",
       "      <td>52244</td>\n",
       "      <td>Parc Px</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transdev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>668589.1929</td>\n",
       "      <td>6.878989e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>Parc PX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT(2.54483189791712 49.0089784609502)</td>\n",
       "      <td>POINT(2.54483189791712 49.0089784609502)</td>\n",
       "      <td>1002</td>\n",
       "      <td>Parc PR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>74162</td>\n",
       "      <td>NC</td>\n",
       "      <td>59080</td>\n",
       "      <td>Parc Pr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transdev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>666700.4738</td>\n",
       "      <td>6.878881e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>Parc PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT(2.56055884390188 49.0100018661511)</td>\n",
       "      <td>POINT(2.56055884390188 49.0100018661511)</td>\n",
       "      <td>1003</td>\n",
       "      <td>Terminal 3 - Roissypole</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>73596</td>\n",
       "      <td>Aéroport CDG 1 (Terminal 3)</td>\n",
       "      <td>462398</td>\n",
       "      <td>Aéroport CDG 1 (Terminal 3) - RER</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transdev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>667851.6587</td>\n",
       "      <td>6.878988e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>Terminal 3 - Roissypole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT(2.34266003733635 48.8846809737278)</td>\n",
       "      <td>POINT(2.34266003733635 48.8846809737278)</td>\n",
       "      <td>1017</td>\n",
       "      <td>Funiculaire Montmartre Station Basse</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>73849</td>\n",
       "      <td>Funiculaire de Montmartre - Gare basse</td>\n",
       "      <td>45559</td>\n",
       "      <td>Funiculaire de Montmartre - Gare basse</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUNICULAIRE MONTMART</td>\n",
       "      <td>RATP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>651795.0575</td>\n",
       "      <td>6.865163e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>Funiculaire Montmartre Station Basse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT(2.34254965325849 48.8856611127015)</td>\n",
       "      <td>POINT(2.34254965325849 48.8856611127015)</td>\n",
       "      <td>1018</td>\n",
       "      <td>Funiculaire Montmartre Station Haute</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>73848</td>\n",
       "      <td>Funiculaire de Montmartre - Gare haute</td>\n",
       "      <td>45558</td>\n",
       "      <td>Funiculaire de Montmartre - Gare haute</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUNICULAIRE MONTMART</td>\n",
       "      <td>RATP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>651787.8703</td>\n",
       "      <td>6.865272e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>Funiculaire Montmartre Station Haute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               geo_point_2d  \\\n",
       "0  POINT(2.57064006889043 49.0100449600405)   \n",
       "1  POINT(2.54483189791712 49.0089784609502)   \n",
       "2  POINT(2.56055884390188 49.0100018661511)   \n",
       "3  POINT(2.34266003733635 48.8846809737278)   \n",
       "4  POINT(2.34254965325849 48.8856611127015)   \n",
       "\n",
       "                                  geo_shape  id_gares  \\\n",
       "0  POINT(2.57064006889043 49.0100449600405)      1004   \n",
       "1  POINT(2.54483189791712 49.0089784609502)      1002   \n",
       "2  POINT(2.56055884390188 49.0100018661511)      1003   \n",
       "3  POINT(2.34266003733635 48.8846809737278)      1017   \n",
       "4  POINT(2.34254965325849 48.8856611127015)      1018   \n",
       "\n",
       "                              nom_gares nom_so_gar nom_su_gar  id_ref_zdc  \\\n",
       "0                               Parc PX       None       None       73595   \n",
       "1                               Parc PR       None       None       74162   \n",
       "2               Terminal 3 - Roissypole       None       None       73596   \n",
       "3  Funiculaire Montmartre Station Basse       None       None       73849   \n",
       "4  Funiculaire Montmartre Station Haute       None       None       73848   \n",
       "\n",
       "                                  nom_zdc  id_ref_zda  \\\n",
       "0                                      NC       52244   \n",
       "1                                      NC       59080   \n",
       "2             Aéroport CDG 1 (Terminal 3)      462398   \n",
       "3  Funiculaire de Montmartre - Gare basse       45559   \n",
       "4  Funiculaire de Montmartre - Gare haute       45558   \n",
       "\n",
       "                                  nom_zda  ... termetro tertram  \\\n",
       "0                                 Parc Px  ...        0       0   \n",
       "1                                 Parc Pr  ...        0       0   \n",
       "2       Aéroport CDG 1 (Terminal 3) - RER  ...        0       0   \n",
       "3  Funiculaire de Montmartre - Gare basse  ...        0       0   \n",
       "4  Funiculaire de Montmartre - Gare haute  ...        0       0   \n",
       "\n",
       "                 terval exploitant idf principal            x             y  \\\n",
       "0                     0   Transdev   1         0  668589.1929  6.878989e+06   \n",
       "1                     0   Transdev   1         0  666700.4738  6.878881e+06   \n",
       "2                     0   Transdev   1         0  667851.6587  6.878988e+06   \n",
       "3  FUNICULAIRE MONTMART       RATP   1         0  651795.0575  6.865163e+06   \n",
       "4  FUNICULAIRE MONTMART       RATP   1         0  651787.8703  6.865272e+06   \n",
       "\n",
       "  picto                                nom_iv  \n",
       "0  None                               Parc PX  \n",
       "1  None                               Parc PR  \n",
       "2  None               Terminal 3 - Roissypole  \n",
       "3  None  Funiculaire Montmartre Station Basse  \n",
       "4  None  Funiculaire Montmartre Station Haute  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vérification de la table chargée\n",
    "table = bq_client.get_table(table_id)\n",
    "print(f\"[OK] - Nombre total de lignes: {table.num_rows}\")\n",
    "print(f\"[OK] - Colonnes:\")\n",
    "for field in table.schema:\n",
    "    print(f\"  - {field.name}: {field.field_type}\")\n",
    "\n",
    "# Requête simple pour vérifier les données et convertir en DataFrame pandas\n",
    "query = f\"SELECT * FROM `{table_id}` LIMIT 5\"\n",
    "results = bq_client.query(query).result()\n",
    "df = results.to_dataframe()\n",
    "\n",
    "print(f\"\\n[OK] - Aperçu des données (5 premières lignes):\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2937e",
   "metadata": {},
   "source": [
    "### 2.3 - Table `dim_ligne` (Référentiel des Lignes)\n",
    "\n",
    "Cette table contient les informations sur toutes les lignes de transport en commun d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les lignes (numéros, noms, types de transport, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd796e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet vers univ-reims-sncf-forecast.silver.dim_ligne...\n",
      "[OK] - 2120 lignes chargées dans univ-reims-sncf-forecast.silver.dim_ligne\n",
      "[OK] - Taille: 0.56 MB\n"
     ]
    }
   ],
   "source": [
    "gcs_path_lignes = \"bronze/referentiel-des-lignes/referentiel-des-lignes.parquet\"\n",
    "table_id_lignes = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_lignes,\n",
    "    table_name=\"dim_ligne\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a769c",
   "metadata": {},
   "source": [
    "### 2.4 - Table `dim_arret` (Référentiel des Arrêts)\n",
    "\n",
    "Cette table contient les informations sur tous les arrêts de transport en commun d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les arrêts (noms, coordonnées, lignes desservies, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e16ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/arrets/arrets.parquet vers univ-reims-sncf-forecast.silver.dim_arret...\n",
      "[OK] - 38619 lignes chargées dans univ-reims-sncf-forecast.silver.dim_arret\n",
      "[OK] - Taille: 6.34 MB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "gcs_path_arrets = \"bronze/arrets/arrets.parquet\"\n",
    "table_id_arrets = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_arrets,\n",
    "    table_name=\"dim_arret\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3adda",
   "metadata": {},
   "source": [
    "### 2.5 - Table `dim_transporteur` (Liste des Transporteurs)\n",
    "\n",
    "Cette table contient les informations sur tous les transporteurs (opérateurs de transport) d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les transporteurs (noms, codes, types de transport, etc.)\n",
    "\n",
    "**Note** : Cette table de dimension permet d'identifier les différents opérateurs de transport qui gèrent les lignes et arrêts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e46fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/liste-transporteurs/liste-transporteurs.parquet vers univ-reims-sncf-forecast.silver.dim_transporteur...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m gcs_path_transporteurs = \u001b[33m\"\u001b[39m\u001b[33mbronze/liste-transporteurs/liste-transporteurs.parquet\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m table_id_transporteurs = \u001b[43mload_parquet_from_gcs\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgcs_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgcs_path_transporteurs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdim_transporteur\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbq_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbq_client\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATASET_ID\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBUCKET_NAME\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Autodetect\u001b[39;49;00m\n",
      "\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n",
      "\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/src/bq_utils.py:59\u001b[39m, in \u001b[36mload_parquet_from_gcs\u001b[39m\u001b[34m(gcs_path, table_name, bq_client, project_id, dataset_id, bucket_name, schema, primary_key, write_disposition)\u001b[39m\n",
      "\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m     57\u001b[39m     job_config.autodetect = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m load_job = \u001b[43mbq_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_table_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcs_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     60\u001b[39m load_job.result()\n",
      "\u001b[32m     62\u001b[39m table = bq_client.get_table(table_id)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/client.py:2573\u001b[39m, in \u001b[36mClient.load_table_from_uri\u001b[39m\u001b[34m(self, source_uris, destination, job_id, job_id_prefix, location, project, job_config, retry, timeout)\u001b[39m\n",
      "\u001b[32m   2570\u001b[39m new_job_config = job_config._fill_from_default(\u001b[38;5;28mself\u001b[39m._default_load_job_config)\n",
      "\u001b[32m   2572\u001b[39m load_job = job.LoadJob(job_ref, source_uris, destination, \u001b[38;5;28mself\u001b[39m, new_job_config)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2573\u001b[39m \u001b[43mload_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m load_job\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/job/base.py:825\u001b[39m, in \u001b[36m_AsyncJob._begin\u001b[39m\u001b[34m(self, client, retry, timeout)\u001b[39m\n",
      "\u001b[32m    822\u001b[39m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n",
      "\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n",
      "\u001b[32m    824\u001b[39m span_attributes = {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path}\n",
      "\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m api_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBigQuery.job.begin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_api_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    835\u001b[39m \u001b[38;5;28mself\u001b[39m._set_properties(api_response)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/client.py:861\u001b[39m, in \u001b[36mClient._call_api\u001b[39m\u001b[34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[39m\n",
      "\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n",
      "\u001b[32m    859\u001b[39m         name=span_name, attributes=span_attributes, client=\u001b[38;5;28mself\u001b[39m, job_ref=job_ref\n",
      "\u001b[32m    860\u001b[39m     ):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    863\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n",
      "\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n",
      "\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n",
      "\u001b[32m    293\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n",
      "\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/_http/__init__.py:482\u001b[39m, in \u001b[36mJSONConnection.api_request\u001b[39m\u001b[34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[39m\n",
      "\u001b[32m    479\u001b[39m     data = json.dumps(data)\n",
      "\u001b[32m    480\u001b[39m     content_type = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_target_object\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_api_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_api_info\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= response.status_code < \u001b[32m300\u001b[39m:\n",
      "\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_http_response(response)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/_http/__init__.py:341\u001b[39m, in \u001b[36mJSONConnection._make_request\u001b[39m\u001b[34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[39m\n",
      "\u001b[32m    338\u001b[39m     headers[CLIENT_INFO_HEADER] = \u001b[38;5;28mself\u001b[39m.user_agent\n",
      "\u001b[32m    339\u001b[39m headers[\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.user_agent\n",
      "\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_request\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n",
      "\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/_http/__init__.py:379\u001b[39m, in \u001b[36mJSONConnection._do_request\u001b[39m\u001b[34m(self, method, url, headers, data, target_object, timeout)\u001b[39m\n",
      "\u001b[32m    345\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_request\u001b[39m(\n",
      "\u001b[32m    346\u001b[39m     \u001b[38;5;28mself\u001b[39m, method, url, headers, data, target_object, timeout=_DEFAULT_TIMEOUT\n",
      "\u001b[32m    347\u001b[39m ):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n",
      "\u001b[32m    348\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Low-level helper:  perform the actual API request over HTTP.\u001b[39;00m\n",
      "\u001b[32m    349\u001b[39m \n",
      "\u001b[32m    350\u001b[39m \u001b[33;03m    Allows batch context managers to override and defer a request.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m    :returns: The HTTP response.\u001b[39;00m\n",
      "\u001b[32m    378\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n",
      "\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/auth/transport/requests.py:535\u001b[39m, in \u001b[36mAuthorizedSession.request\u001b[39m\u001b[34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[39m\n",
      "\u001b[32m    533\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n",
      "\u001b[32m    534\u001b[39m     _helpers.request_log(_LOGGER, method, url, data, headers)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n",
      "\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    543\u001b[39m remaining_time = guard.remaining_timeout\n",
      "\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n",
      "\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n",
      "\u001b[32m    547\u001b[39m \u001b[38;5;66;03m# request.\u001b[39;00m\n",
      "\u001b[32m    548\u001b[39m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n",
      "\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n",
      "\u001b[32m    584\u001b[39m send_kwargs = {\n",
      "\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n",
      "\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n",
      "\u001b[32m    587\u001b[39m }\n",
      "\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n",
      "\u001b[32m    700\u001b[39m start = preferred_clock()\n",
      "\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n",
      "\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n",
      "\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n",
      "\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n",
      "\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n",
      "\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n",
      "\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n",
      "\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n",
      "\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n",
      "\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.14/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n",
      "\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "gcs_path_transporteurs = \"bronze/liste-transporteurs/liste-transporteurs.parquet\"\n",
    "table_id_transporteurs = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_transporteurs,\n",
    "    table_name=\"dim_transporteur\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9d463",
   "metadata": {},
   "source": [
    "### 2.5 - Table `dim_vacances_scolaires` (Calendrier des Vacances Scolaires)\n",
    "\n",
    "Cette table contient les périodes de vacances scolaires pour différentes zones et années.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : CSV (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Encodage** : UTF-8\n",
    "- **Séparateur** : Point-virgule (`;`)\n",
    "- **Contenu** : Dates de début/fin de vacances, zones, années, etc.\n",
    "\n",
    "**Note** : Pour les fichiers CSV, il est important de spécifier l'encodage et le séparateur pour éviter les erreurs de parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b4660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/vacances-scolaires/vacances_scolaires.csv vers univ-reims-sncf-forecast.silver.dim_vacances_scolaires...\n",
      "[OK] - 2306 lignes chargées dans univ-reims-sncf-forecast.silver.dim_vacances_scolaires\n",
      "[OK] - Taille: 0.16 MB\n"
     ]
    }
   ],
   "source": [
    "gcs_path_vacances = \"bronze/vacances-scolaires/vacances_scolaires.csv\"\n",
    "table_id_vacances = load_csv_from_gcs(\n",
    "    gcs_path=gcs_path_vacances,\n",
    "    table_name=\"dim_vacances_scolaires\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    skip_leading_rows=1,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\";\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e9487",
   "metadata": {},
   "source": [
    "## 3 - Chargement des Tables de Fait\n",
    "\n",
    "Les tables de fait contiennent les mesures et événements métier. Ici, nous chargeons les données historiques de validations des titres de transport.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 - Configuration pour les Fichiers de Validation\n",
    "\n",
    "Les fichiers de validation historiques ont des formats différents selon les années :\n",
    "- **Encodages variés** : UTF-8, UTF-16LE, Latin-1\n",
    "- **Séparateurs variés** : Tabulation (`\\t`), point-virgule (`;`)\n",
    "- **Extensions variées** : `.txt`, `.csv`\n",
    "\n",
    "Ce dictionnaire de configuration permet de spécifier les paramètres corrects pour chaque fichier.\n",
    "\n",
    "**Note importante** : Le fichier `2023_S2_NB_FER.txt` utilise l'encodage UTF-16LE, qui n'est pas supporté directement par BigQuery. La fonction `load_csv_from_gcs` convertit automatiquement ce fichier en UTF-8 avant le chargement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d04b8",
   "metadata": {},
   "source": [
    "### 3.2 - Chargement des Fichiers de Validation\n",
    "\n",
    "Cette section charge tous les fichiers de validation historiques depuis GCS vers BigQuery.\n",
    "\n",
    "**Processus :**\n",
    "1. Parcourt le dictionnaire de configuration\n",
    "2. Recherche chaque fichier dans GCS\n",
    "3. Charge le fichier avec les paramètres appropriés (encodage, séparateur, format de date)\n",
    "4. Crée une table séparée pour chaque fichier (ex: `fact_validations_2015s1_nb_fer_csv`)\n",
    "\n",
    "**Gestion spéciale :**\n",
    "- **Fichiers UTF-16LE** : Conversion automatique en UTF-8 (nécessite `storage_client`)\n",
    "- **Format de date** : `DD/MM/YYYY` (format BigQuery pour les dates françaises)\n",
    "- **Schéma** : Auto-détecté (toutes les colonnes en STRING pour éviter les erreurs de parsing)\n",
    "\n",
    "**Durée estimée** : Plusieurs minutes selon le nombre et la taille des fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c38873",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_rf_config = {\n",
    "    \"2015S1_NB_FER.csv\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2015S2_NB_FER.csv\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2016S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2016S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2017S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2017_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2018_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2019_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2019_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2020_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2020_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2021_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2021_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2022_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2022_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2023_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-16le\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2024_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e86c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S1_NB_FER.csv vers univ-reims-sncf-forecast.silver.fact_validations_2015s1_nb_fer_csv...\n",
      "[OK] - 755989 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2015s1_nb_fer_csv\n",
      "[OK] - Taille: 45.93 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S2_NB_FER.csv vers univ-reims-sncf-forecast.silver.fact_validations_2015s2_nb_fer_csv...\n",
      "[OK] - 778747 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2015s2_nb_fer_csv\n",
      "[OK] - Taille: 47.28 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2016s1_nb_fer_txt...\n",
      "[OK] - 779712 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2016s1_nb_fer_txt\n",
      "[OK] - Taille: 52.96 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2016s2_nb_fer_txt...\n",
      "[OK] - 774421 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2016s2_nb_fer_txt\n",
      "[OK] - Taille: 52.59 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2017s1_nb_fer_txt...\n",
      "[OK] - 780270 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2017s1_nb_fer_txt\n",
      "[OK] - Taille: 53.02 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017_S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2017_s2_nb_fer_txt...\n",
      "[OK] - 825698 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2017_s2_nb_fer_txt\n",
      "[OK] - Taille: 52.00 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2018_s1_nb_fer_txt...\n",
      "[OK] - 866694 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2018_s1_nb_fer_txt\n",
      "[OK] - Taille: 54.94 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2019_s1_nb_fer_txt...\n",
      "[OK] - 934851 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2019_s1_nb_fer_txt\n",
      "[OK] - Taille: 59.47 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2019_s2_nb_fer_txt...\n",
      "[OK] - 953454 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2019_s2_nb_fer_txt\n",
      "[OK] - Taille: 60.98 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2020_s1_nb_fer_txt...\n",
      "[OK] - 887493 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2020_s1_nb_fer_txt\n",
      "[OK] - Taille: 56.89 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2020_s2_nb_fer_txt...\n",
      "[OK] - 1054012 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2020_s2_nb_fer_txt\n",
      "[OK] - Taille: 67.52 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2021_s1_nb_fer_txt...\n",
      "[OK] - 1064019 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2021_s1_nb_fer_txt\n",
      "[OK] - Taille: 68.20 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2021_s2_nb_fer_txt...\n",
      "[OK] - 1084281 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2021_s2_nb_fer_txt\n",
      "[OK] - Taille: 69.54 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2022_s1_nb_fer_txt...\n",
      "[OK] - 1088334 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2022_s1_nb_fer_txt\n",
      "[OK] - Taille: 69.80 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S2_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2022_s2_nb_fer_txt...\n",
      "[OK] - 1105947 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2022_s2_nb_fer_txt\n",
      "[OK] - Taille: 69.08 MB\n",
      "\n",
      "[...] - Conversion UTF-16LE -> UTF-8 pour bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt...\n",
      "[OK] - Fichier converti et uploadé vers bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8 vers univ-reims-sncf-forecast.silver.fact_validations_2023_s2_nb_fer_txt...\n",
      "[OK] - 849596 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2023_s2_nb_fer_txt\n",
      "[OK] - Taille: 62.86 MB\n",
      "[OK] - Fichier temporaire bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8 supprimé\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/2024/2024_S1_NB_FER.txt vers univ-reims-sncf-forecast.silver.fact_validations_2024_s1_nb_fer_txt...\n",
      "[OK] - 859043 lignes chargées dans univ-reims-sncf-forecast.silver.fact_validations_2024_s1_nb_fer_txt\n",
      "[OK] - Taille: 63.60 MB\n"
     ]
    }
   ],
   "source": [
    "# Charger tous les fichiers de validation depuis GCS vers BigQuery\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Parcourir tous les fichiers dans la configuration\n",
    "for filename, config in load_rf_config.items():\n",
    "    # Chercher le fichier dans GCS\n",
    "    blobs = list(bucket.list_blobs(prefix=\"bronze/histo-validations-reseau-ferre/\"))\n",
    "    \n",
    "    # Trouver le blob correspondant\n",
    "    blob = None\n",
    "    for b in blobs:\n",
    "        if b.name.endswith(filename):\n",
    "            blob = b\n",
    "            break\n",
    "    \n",
    "    if blob is None:\n",
    "        print(f\"[SKIP] - {filename} (non trouvé dans GCS)\")\n",
    "        continue\n",
    "    \n",
    "    gcs_path = blob.name\n",
    "    table_name = f\"fact_validations_{filename.replace('.', '_').replace('-', '_').lower()}\"\n",
    "    \n",
    "    sep = config[\"sep\"]\n",
    "    encoding = config[\"encoding\"]\n",
    "    \n",
    "    # Convertir \"\\t\" en tabulation réelle si nécessaire\n",
    "    if sep == \"\\\\t\":\n",
    "        sep = \"\\t\"\n",
    "    \n",
    "    # Utiliser la fonction load_csv_from_gcs avec le schéma unifié (toutes les colonnes en STRING)\n",
    "    table_id = load_csv_from_gcs(\n",
    "        gcs_path=gcs_path,\n",
    "        table_name=table_name,\n",
    "        bq_client=bq_client,\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        schema=None,\n",
    "        skip_leading_rows=config.get(\"skip_rows\", 1),\n",
    "        encoding=encoding,\n",
    "        sep=sep,\n",
    "        date_format=\"DD/MM/YYYY\",  # Format BigQuery pour les dates\n",
    "        storage_client=storage_client,  # Requis pour la conversion UTF-16LE\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
