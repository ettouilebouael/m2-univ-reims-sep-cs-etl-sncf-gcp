{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3 : Analyse pour la Construction de la Couche Gold\n",
        "\n",
        "## Objectif\n",
        "\n",
        "Ce notebook vous guide dans l'**analyse des données de la couche silver** pour préparer la construction de la couche **gold** (analytics/BI/ML).\n",
        "\n",
        "La couche gold contient des données transformées, nettoyées et optimisées pour l'analyse métier et la création de rapports/dashboards.\n",
        "\n",
        "## Prérequis\n",
        "\n",
        "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
        "\n",
        "1. **Exécuté le notebook `2_[LOAD]_load_to_bigquery.ipynb`** pour avoir toutes les tables dans BigQuery (dataset `silver`)\n",
        "2. **Fichier `.env` configuré** avec les variables d'environnement nécessaires\n",
        "3. **Service Account** avec les permissions BigQuery (`BigQuery Data Viewer`, `BigQuery Job User`)\n",
        "4. **Packages Python installés** : `google-cloud-bigquery`, `pandas`, etc.\n",
        "\n",
        "## Structure du Notebook\n",
        "\n",
        "Ce notebook contient **4 tâches principales** à réaliser :\n",
        "\n",
        "1. **Tâche 1 : Analyser la Granularité** - Comprendre le niveau de détail de chaque table\n",
        "2. **Tâche 2 : Identifier les Transformations** - Déterminer les transformations nécessaires pour la couche gold\n",
        "3. **Tâche 3 : Identifier les Clés de Jointure** - Mapper les relations entre les tables\n",
        "4. **Tâche 4 : Analyse métier Identifier les **KPIs** métiers - \n",
        "\n",
        "## Résultats Attendus\n",
        "\n",
        "À la fin de ce notebook, vous devriez avoir :\n",
        "- Une compréhension claire de la structure et de la granularité de chaque table\n",
        "- Une liste des transformations à appliquer pour créer la couche gold\n",
        "- Un schéma de jointures documenté"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration et Connexion à BigQuery\n",
        "\n",
        "Cette section configure l'environnement et établit la connexion avec BigQuery pour explorer les données de la couche silver.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] - Connecté au projet: univ-reims-sncf-forecast\n",
            "[OK] - Dataset: silver\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Third-party imports\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Configuration\n",
        "load_dotenv()\n",
        "\n",
        "ROOT = Path.cwd().parent\n",
        "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
        "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "DATASET_ID = \"silver\"\n",
        "\n",
        "# Authentification\n",
        "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
        "\n",
        "print(f\"[OK] - Connecté au projet: {PROJECT_ID}\")\n",
        "print(f\"[OK] - Dataset: {DATASET_ID}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 1 : Analyser la Granularité de Chaque Table\n",
        "\n",
        "### Objectif\n",
        "\n",
        "La **granularité** d'une table correspond au niveau de détail des données qu'elle contient. Comprendre la granularité est essentiel pour :\n",
        "- Déterminer comment agréger les données\n",
        "- Identifier les duplications potentielles\n",
        "- Comprendre le niveau de détail nécessaire pour les analyses métier\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque table du dataset `silver`, vous devez :\n",
        "\n",
        "1. **Lister les colonnes** et leurs types\n",
        "2. **Identifier les clés primaires** ou les colonnes qui identifient de manière unique une ligne\n",
        "3. **Déterminer la granularité** : à quel niveau de détail sont les données ?\n",
        "   - Exemple : `fact_validations` pourrait être au niveau **jour × gare × type de titre**\n",
        "4. **Compter les lignes** et estimer la taille des données\n",
        "5. **Identifier les colonnes de dimension** (références vers d'autres tables)\n",
        "\n",
        "### Exemple de Format de Réponse\n",
        "\n",
        "```\n",
        "Table: dim_gare\n",
        "- Granularité: 1 ligne = 1 gare\n",
        "- Clé primaire: id_gares\n",
        "- Nombre de lignes: 1234\n",
        "- Colonnes de dimension: aucune (table de dimension)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### À Compléter : Analyse de Granularité\n",
        "\n",
        "**Tables de Dimension :**\n",
        "\n",
        "1. `dim_gare`\n",
        "2. `dim_ligne`\n",
        "3. `dim_arret`\n",
        "4. `dim_vacances_scolaires`\n",
        "5. `dim_transporteur`\n",
        "\n",
        "**Tables de Fait :**\n",
        "\n",
        "6. `fact_validations_*` (toutes les tables de validation)\n",
        "\n",
        "**Votre tâche :** Exécutez des requêtes SQL pour analyser chaque table et remplir le tableau ci-dessous.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Analyse de dim_gare ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/admin/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nb_lignes</th>\n",
              "      <th>nb_gares_uniques</th>\n",
              "      <th>nb_id_null</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1234</td>\n",
              "      <td>1231</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nb_lignes  nb_gares_uniques  nb_id_null\n",
              "0       1234              1231           0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Schéma ===\n",
            "  - geo_point_2d: GEOGRAPHY (NULLABLE)\n",
            "  - geo_shape: GEOGRAPHY (NULLABLE)\n",
            "  - id_gares: INTEGER (REQUIRED)\n",
            "  - nom_gares: STRING (NULLABLE)\n",
            "  - nom_so_gar: STRING (NULLABLE)\n",
            "  - nom_su_gar: STRING (NULLABLE)\n",
            "  - id_ref_zdc: INTEGER (NULLABLE)\n",
            "  - nom_zdc: STRING (NULLABLE)\n",
            "  - id_ref_zda: INTEGER (NULLABLE)\n",
            "  - nom_zda: STRING (NULLABLE)\n",
            "  - idrefliga: STRING (NULLABLE)\n",
            "  - idrefligc: STRING (NULLABLE)\n",
            "  - res_com: STRING (NULLABLE)\n",
            "  - indice_lig: STRING (NULLABLE)\n",
            "  - mode: STRING (NULLABLE)\n",
            "  - tertrain: STRING (NULLABLE)\n",
            "  - terrer: STRING (NULLABLE)\n",
            "  - termetro: STRING (NULLABLE)\n",
            "  - tertram: STRING (NULLABLE)\n",
            "  - terval: STRING (NULLABLE)\n",
            "  - exploitant: STRING (NULLABLE)\n",
            "  - idf: INTEGER (NULLABLE)\n",
            "  - principal: INTEGER (NULLABLE)\n",
            "  - x: FLOAT (NULLABLE)\n",
            "  - y: FLOAT (NULLABLE)\n",
            "  - picto: STRING (NULLABLE)\n",
            "  - nom_iv: STRING (NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Exemple : Analyser la table dim_gare\n",
        "query = f\"\"\"\n",
        "Votre code ici\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Analyse de dim_gare ===\")\n",
        "display(df)\n",
        "\n",
        "# Afficher le schéma\n",
        "table = bq_client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.dim_gare\")\n",
        "print(\"\\n=== Schéma ===\")\n",
        "for field in table.schema:\n",
        "    print(f\"  - {field.name}: {field.field_type} ({field.mode})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 2 : Identifier les Transformations Nécessaires\n",
        "\n",
        "### Objectif\n",
        "\n",
        "Identifier les **transformations** à appliquer aux données de la couche silver pour créer la couche gold optimisée pour l'analyse.\n",
        "\n",
        "### Types de Transformations Possibles\n",
        "\n",
        "1. **Nettoyage des données**\n",
        "   - Suppression des doublons\n",
        "   - Gestion des valeurs NULL\n",
        "   - Normalisation des formats (dates, textes)\n",
        "\n",
        "2. **Enrichissement**\n",
        "   - Ajout de colonnes calculées\n",
        "   - Jointures avec les tables de dimension\n",
        "   - Ajout de catégories/segments\n",
        "\n",
        "3. **Agrégation**\n",
        "   - Regroupement par dimensions (jour, gare, ligne, etc.)\n",
        "   - Calcul de métriques (somme, moyenne, comptage)\n",
        "   - Création de tables pré-agrégées\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque table, identifiez :\n",
        "1. **Les problèmes de qualité** à corriger\n",
        "2. **Les transformations nécessaires** avec des exemples concrets\n",
        "3. **Les colonnes à ajouter** (calculées ou issues de jointures)\n",
        "4. **Les agrégations possibles** pour optimiser les requêtes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Exemple : Recherche de doublons ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/admin/.pyenv/versions/3.11.14/envs/etl-gcp/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JOUR</th>\n",
              "      <th>ID_ZDC</th>\n",
              "      <th>CATEGORIE_TITRE</th>\n",
              "      <th>nb_occurrences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-11-03</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-11-06</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-11-08</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-11-09</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-11-12</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2023-11-14</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2023-11-17</td>\n",
              "      <td>999999</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>71379</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2023-07-02</td>\n",
              "      <td>71379</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023-07-03</td>\n",
              "      <td>71379</td>\n",
              "      <td>Amethyste</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         JOUR  ID_ZDC CATEGORIE_TITRE  nb_occurrences\n",
              "0  2023-11-03  999999       Amethyste               2\n",
              "1  2023-11-06  999999       Amethyste               2\n",
              "2  2023-11-08  999999       Amethyste               2\n",
              "3  2023-11-09  999999       Amethyste               2\n",
              "4  2023-11-12  999999       Amethyste               2\n",
              "5  2023-11-14  999999       Amethyste               2\n",
              "6  2023-11-17  999999       Amethyste               2\n",
              "7  2023-07-01   71379       Amethyste               2\n",
              "8  2023-07-02   71379       Amethyste               2\n",
              "9  2023-07-03   71379       Amethyste               2"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exemple 1 : Vérifier les doublons dans fact_validations\n",
        "query = f\"\"\"\n",
        "Votre code ici\n",
        "\"\"\"\n",
        "\n",
        "df_duplicates = bq_client.query(query).to_dataframe()\n",
        "print(\"=== Exemple : Recherche de doublons ===\")\n",
        "display(df_duplicates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 3 : Identifier les Clés de Jointure Possibles\n",
        "\n",
        "### Objectif\n",
        "\n",
        "Identifier toutes les **relations possibles** entre les tables pour pouvoir créer des jointures dans la couche gold.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Pour chaque paire de tables, identifiez :\n",
        "\n",
        "1. **Les colonnes de jointure** (clés étrangères)\n",
        "2. **Le type de relation** (1-1, 1-N, N-N)\n",
        "3. **La cardinalité** (combien de lignes de la table A correspondent à combien de lignes de la table B)\n",
        "4. **Vérifier l'intégrité référentielle** (toutes les clés étrangères existent-elles dans la table de dimension ?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tâche 4 : Analyse métier\n",
        "\n",
        "Identifier les **KPIs** (Key Performance Indicators) à calculer :\n",
        "- Nombre total de validations par période\n",
        "- Répartition par type de titre\n",
        "- Top 10 des gares les plus fréquentées\n",
        "- Comparaison jour ouvrable vs weekend\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "etl-gcp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
