{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f8bdd9",
   "metadata": {},
   "source": [
    "# Notebook 0 : Test de Connexion aux Services GCP\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Ce notebook permet de **vérifier la configuration et la connexion** aux services Google Cloud Platform (GCP) nécessaires pour le projet ETL :\n",
    "- **Google Cloud Storage (GCS)** : pour le stockage des données brutes (couche \"bronze\")\n",
    "- **BigQuery** : pour le traitement et le stockage des données transformées (couche \"silver\")\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
    "\n",
    "1. **Fichier `.env` configuré** à la racine du projet avec :\n",
    "   - `PROJECT_ID` : l'identifiant de votre projet GCP\n",
    "   - `GOOGLE_APPLICATION_CREDENTIALS` : le chemin vers votre fichier de credentials JSON\n",
    "   - `BUCKET_NAME` : le nom de votre bucket GCS\n",
    "\n",
    "2. **Service Account** avec les permissions suivantes :\n",
    "   - `Storage Object Viewer` ou `Storage Admin` pour GCS\n",
    "   - `BigQuery Data Viewer` et `BigQuery Job User` pour BigQuery\n",
    "\n",
    "3. **Packages Python installés** :\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c29233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage, bigquery\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "# Id du projet\n",
    "PROJECT_ID  = os.getenv(\"PROJECT_ID\")\n",
    "# Configuration du service account\n",
    "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "# Configuration du bucket GCS\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f64af",
   "metadata": {},
   "source": [
    "## 1 - Configuration\n",
    "- Chargement des variables d'environnement depuis `.env`\n",
    "- Initialisation des chemins et identifiants du projet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbcc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Charger les credentials du fichier JSON\n",
    "creds = service_account.Credentials.from_service_account_file(SA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c062924",
   "metadata": {},
   "source": [
    "## 2 - Test de Connexion GCS\n",
    "- Authentification avec le Service Account\n",
    "- Vérification de l'accès au projet\n",
    "- Listing des buckets disponibles\n",
    "- **Inspection du bucket** : affichage de tous les fichiers stockés dans le bucket configuré\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5efead90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth OK - storage : univ-reims-sncf-forecast\n",
      "Liste des buckets : [<Bucket: bronze-sncf-etl>]\n",
      "Fichiers dans le bucket 'bronze-sncf-etl':\n",
      "--------------------------------------------------\n",
      "[FILE] bronze/arrets/arrets.parquet\n",
      "[FILE] bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S1_NB_FER.csv\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S1_PROFIL_FER.csv\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S2_NB_FER.csv\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S2_PROFIL_FER.csv\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S2_NB_Fer.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S2_Profil_Fer.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S1_NB_FER .txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_PROFIL_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2024/2024_S1_NB_FER.txt\n",
      "[FILE] bronze/histo-validations-reseau-ferre/2024/2024_S1_PROFIL_FER.txt\n",
      "[FILE] bronze/jours-feries/jours_feries_2015.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2016.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2017.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2018.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2019.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2020.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2021.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2022.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2023.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2024.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2025.json\n",
      "[FILE] bronze/jours-feries/jours_feries_2026.json\n",
      "[FILE] bronze/referentiel-des-lignes/referentiel-des-lignes.parquet\n",
      "[FILE] bronze/vacances-scolaires/vacances_scolaires.csv\n",
      "[FILE] bronze/vacances-scolaires/vacances_scolaires.json\n",
      "\n",
      "Total: 55 fichiers trouvés\n"
     ]
    }
   ],
   "source": [
    "# 2) Créer le client GCS\n",
    "st = storage.Client(project=PROJECT_ID, credentials=creds)\n",
    "\n",
    "print(f\"Auth OK - storage : {st.project}\")\n",
    "print(f\"Liste des buckets : {list(st.list_buckets())}\")\n",
    "\n",
    "# Lister les fichiers dans le bucket\n",
    "bucket = st.bucket(BUCKET_NAME)\n",
    "print(f\"Fichiers dans le bucket '{BUCKET_NAME}':\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "blobs = bucket.list_blobs()\n",
    "file_count = 0\n",
    "\n",
    "for blob in blobs:\n",
    "    print(f\"[FILE] {blob.name}\")\n",
    "    file_count += 1\n",
    "\n",
    "print(f\"\\nTotal: {file_count} fichiers trouvés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4ec99",
   "metadata": {},
   "source": [
    "## 3) - Test de Connexion BigQuery\n",
    "- Création du client BigQuery\n",
    "- **Vérification du projet** : confirmation de l'accès au projet\n",
    "- **Listing des datasets** : affichage de tous les datasets disponibles\n",
    "- **Test d'exécution SQL** : exécution d'une requête simple pour valider les permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296eac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] - Projet BigQuery: univ-reims-sncf-forecast\n",
      "\n",
      "[...] - Liste des datasets dans le projet:\n",
      "  - silver\n",
      "\n",
      "[...] - Test d'exécution d'une requête SQL...\n",
      "    [OK] - Requête exécutée avec succès\n",
      "         - Test value: 1\n",
      "         - Timestamp: 2025-11-17 20:37:26.565341+00:00\n"
     ]
    }
   ],
   "source": [
    "# 3) Créer le client BigQuery\n",
    "bq = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
    "\n",
    "# Test 1: Vérifier le projet\n",
    "print(f\"\\n[OK] - Projet BigQuery: {bq.project}\")\n",
    "\n",
    "# Test 2: Lister les datasets\n",
    "print(f\"\\n[...] - Liste des datasets dans le projet:\")\n",
    "datasets = list(bq.list_datasets())\n",
    "if datasets:\n",
    "    for dataset in datasets:\n",
    "        print(f\"  - {dataset.dataset_id}\")\n",
    "else:\n",
    "    print(\"  (Aucun dataset trouvé)\")\n",
    "\n",
    "# Test 3: Exécuter une requête simple\n",
    "print(f\"\\n[...] - Test d'exécution d'une requête SQL...\")\n",
    "query = \"SELECT 1 as test_value, CURRENT_TIMESTAMP() as timestamp\"\n",
    "results = bq.query(query).result()\n",
    "for row in results:\n",
    "    print(f\"    [OK] - Requête exécutée avec succès\")\n",
    "    print(f\"         - Test value: {row.test_value}\")\n",
    "    print(f\"         - Timestamp: {row.timestamp}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
